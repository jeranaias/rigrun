// Copyright (c) 2024-2025 Jesse Morgan
// Licensed under the MIT License. See LICENSE file for details.

//! Unified Setup Module for rigrun
//!
//! Provides a single `rigrun setup` command that replaces 6 conflicting docs
//! and 20+ manual steps with ONE command that just works.
//!
//! # Usage
//!
//! ```bash
//! # Quick setup (5 minutes to productive)
//! rigrun setup --quick
//!
//! # Full setup with all features
//! rigrun setup --full
//!
//! # Force specific hardware mode
//! rigrun setup --hardware nvidia
//! rigrun setup --hardware amd
//! rigrun setup --hardware cpu
//! ```
//!
//! # What it does
//!
//! 1. Checks prerequisites (Rust, Ollama, disk space, RAM)
//! 2. Detects GPU and configures optimal settings
//! 3. Generates secure config.toml with sensible defaults
//! 4. Downloads the best model for your hardware
//! 5. Runs health checks to verify everything works
//! 6. Provides clear next steps

use anyhow::{Context, Result};
use rand::Rng;
use serde::{Deserialize, Serialize};
use std::fs;
use std::io::{self, Write};
use std::path::PathBuf;
use std::process::Command;
use std::time::{Duration, Instant};

use crate::detect::{
    detect_gpu, recommend_model, GpuInfo, GpuType, AmdArchitecture,
    detect_amd_architecture, check_ollama_available, is_model_available,
};
use crate::local::{OllamaClient, PullProgress};

// ANSI color codes
mod colors {
    pub const RESET: &str = "\x1b[0m";
    pub const BOLD: &str = "\x1b[1m";
    pub const DIM: &str = "\x1b[2m";
    pub const RED: &str = "\x1b[31m";
    pub const GREEN: &str = "\x1b[32m";
    pub const YELLOW: &str = "\x1b[33m";
    pub const BLUE: &str = "\x1b[34m";
    pub const CYAN: &str = "\x1b[36m";
    pub const WHITE: &str = "\x1b[37m";
    pub const BRIGHT_CYAN: &str = "\x1b[96m";
}

use colors::*;

/// Hardware detection mode for setup
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum HardwareMode {
    /// Auto-detect the best hardware configuration
    Auto,
    /// Force NVIDIA GPU mode
    Nvidia,
    /// Force AMD GPU mode
    Amd,
    /// Force CPU-only mode
    Cpu,
}

impl std::str::FromStr for HardwareMode {
    type Err = String;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        match s.to_lowercase().as_str() {
            "auto" => Ok(HardwareMode::Auto),
            "nvidia" => Ok(HardwareMode::Nvidia),
            "amd" => Ok(HardwareMode::Amd),
            "cpu" => Ok(HardwareMode::Cpu),
            _ => Err(format!("Unknown hardware mode: {}. Use: auto, nvidia, amd, or cpu", s)),
        }
    }
}

/// Setup mode: quick (essentials only) or full (all features)
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum SetupMode {
    /// Quick setup - just the essentials to get running
    Quick,
    /// Full setup - all features and optimizations
    Full,
}

/// Configuration file generated by setup
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RigrunConfig {
    /// General settings
    #[serde(default)]
    pub general: GeneralConfig,
    /// Hardware settings
    #[serde(default)]
    pub hardware: HardwareConfig,
    /// Model settings
    #[serde(default)]
    pub model: ModelConfig,
    /// Server settings
    #[serde(default)]
    pub server: ServerConfig,
    /// Security settings
    #[serde(default)]
    pub security: SecurityConfig,
}

impl Default for RigrunConfig {
    fn default() -> Self {
        Self {
            general: GeneralConfig::default(),
            hardware: HardwareConfig::default(),
            model: ModelConfig::default(),
            server: ServerConfig::default(),
            security: SecurityConfig::default(),
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct GeneralConfig {
    /// Version of the config file format
    pub config_version: u32,
    /// When this config was generated
    pub created_at: String,
    /// Whether first-run wizard has completed
    pub first_run_complete: bool,
}

impl Default for GeneralConfig {
    fn default() -> Self {
        Self {
            config_version: 1,
            created_at: chrono::Utc::now().to_rfc3339(),
            first_run_complete: false,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HardwareConfig {
    /// Detected GPU type
    pub gpu_type: String,
    /// GPU name
    pub gpu_name: String,
    /// VRAM in GB
    pub vram_gb: u32,
    /// Whether to use Vulkan backend (for RDNA 4)
    pub use_vulkan: bool,
    /// HSA override version for AMD GPUs
    pub hsa_override: Option<String>,
    /// Optimal batch size for this hardware
    pub batch_size: u32,
    /// Number of GPU layers to offload
    pub gpu_layers: Option<u32>,
}

impl Default for HardwareConfig {
    fn default() -> Self {
        Self {
            gpu_type: "cpu".to_string(),
            gpu_name: "CPU Only".to_string(),
            vram_gb: 0,
            use_vulkan: false,
            hsa_override: None,
            batch_size: 512,
            gpu_layers: None,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelConfig {
    /// Primary model for code generation
    pub primary: String,
    /// Embedding model for semantic search
    pub embedding: String,
    /// Whether to auto-download models
    pub auto_download: bool,
}

impl Default for ModelConfig {
    fn default() -> Self {
        Self {
            primary: "qwen2.5-coder:7b".to_string(),
            embedding: "nomic-embed-text".to_string(),
            auto_download: true,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ServerConfig {
    /// Port to listen on
    pub port: u16,
    /// Host to bind to
    pub host: String,
    /// Enable audit logging
    pub audit_logging: bool,
    /// Paranoid mode (block all cloud requests)
    pub paranoid_mode: bool,
}

impl Default for ServerConfig {
    fn default() -> Self {
        Self {
            port: 8787,
            host: "127.0.0.1".to_string(),
            audit_logging: true,
            paranoid_mode: false,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SecurityConfig {
    /// Secure random API key for local authentication
    pub api_key: String,
    /// OpenRouter API key (optional, for cloud fallback)
    pub openrouter_key: Option<String>,
    /// Whether to require API key for requests
    pub require_auth: bool,
}

impl Default for SecurityConfig {
    fn default() -> Self {
        Self {
            api_key: generate_secure_key(),
            openrouter_key: None,
            require_auth: false, // Default to no auth for local-only use
        }
    }
}

/// Generate a secure random API key
fn generate_secure_key() -> String {
    let mut rng = rand::thread_rng();
    let key: String = (0..32)
        .map(|_| {
            let idx = rng.gen_range(0..62);
            let chars: &[u8] = b"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789";
            chars[idx] as char
        })
        .collect();
    format!("rr-{}", key)
}

/// Result of a prerequisite check
#[derive(Debug)]
pub struct PrerequisiteResult {
    pub name: String,
    pub passed: bool,
    pub message: String,
    pub fix_hint: Option<String>,
}

/// Result of the setup process
#[derive(Debug)]
pub struct SetupResult {
    pub success: bool,
    pub config_path: PathBuf,
    pub model_downloaded: String,
    pub gpu_detected: GpuInfo,
    pub warnings: Vec<String>,
}

/// Main setup orchestrator
pub struct SetupWizard {
    mode: SetupMode,
    hardware_mode: HardwareMode,
    config_dir: PathBuf,
    verbose: bool,
}

impl SetupWizard {
    /// Create a new setup wizard
    pub fn new(mode: SetupMode, hardware_mode: HardwareMode) -> Result<Self> {
        let config_dir = get_config_dir()?;
        Ok(Self {
            mode,
            hardware_mode,
            config_dir,
            verbose: false,
        })
    }

    /// Enable verbose output
    pub fn with_verbose(mut self, verbose: bool) -> Self {
        self.verbose = verbose;
        self
    }

    /// Run the complete setup process
    pub fn run(&self) -> Result<SetupResult> {
        self.print_header();

        // Step 1: Check prerequisites
        println!("{CYAN}[1/6]{RESET} Checking prerequisites...");
        let prereqs = self.check_prerequisites()?;
        let all_passed = prereqs.iter().all(|p| p.passed);

        for prereq in &prereqs {
            if prereq.passed {
                println!("  {GREEN}[OK]{RESET} {}: {}", prereq.name, prereq.message);
            } else {
                println!("  {RED}[X]{RESET} {}: {}", prereq.name, prereq.message);
                if let Some(ref hint) = prereq.fix_hint {
                    println!("      {DIM}Fix: {}{RESET}", hint);
                }
            }
        }

        if !all_passed {
            println!();
            println!("{RED}[!]{RESET} Some prerequisites failed. Please fix them and try again.");
            return Ok(SetupResult {
                success: false,
                config_path: self.config_dir.join("config.toml"),
                model_downloaded: String::new(),
                gpu_detected: GpuInfo::default(),
                warnings: prereqs.iter()
                    .filter(|p| !p.passed)
                    .map(|p| format!("{}: {}", p.name, p.message))
                    .collect(),
            });
        }
        println!();

        // Step 2: Detect and configure hardware
        println!("{CYAN}[2/6]{RESET} Detecting hardware...");
        let (gpu_info, hardware_config) = self.detect_hardware()?;
        self.print_hardware_info(&gpu_info, &hardware_config);
        println!();

        // Step 3: Generate configuration
        println!("{CYAN}[3/6]{RESET} Generating configuration...");
        let config = self.generate_config(&gpu_info, &hardware_config)?;
        let config_path = self.save_config(&config)?;
        println!("  {GREEN}[OK]{RESET} Configuration saved to: {}", config_path.display());
        println!();

        // Step 4: Download required model
        println!("{CYAN}[4/6]{RESET} Downloading model...");
        let model = self.download_model(&config.model.primary)?;
        println!();

        // Step 5: Verify system health
        println!("{CYAN}[5/6]{RESET} Verifying system health...");
        let health_warnings = self.verify_health(&config)?;
        for warning in &health_warnings {
            println!("  {YELLOW}[!]{RESET} {}", warning);
        }
        if health_warnings.is_empty() {
            println!("  {GREEN}[OK]{RESET} All health checks passed");
        }
        println!();

        // Step 6: Show success message
        println!("{CYAN}[6/6]{RESET} Setup complete!");
        self.print_success(&gpu_info, &config_path, &model);

        Ok(SetupResult {
            success: true,
            config_path,
            model_downloaded: model,
            gpu_detected: gpu_info,
            warnings: health_warnings,
        })
    }

    fn print_header(&self) {
        println!();
        println!("{BRIGHT_CYAN}{BOLD}========================================{RESET}");
        println!("{BRIGHT_CYAN}{BOLD}       RigRun Setup Wizard{RESET}");
        println!("{BRIGHT_CYAN}{BOLD}========================================{RESET}");
        println!();
        let mode_str = match self.mode {
            SetupMode::Quick => "Quick",
            SetupMode::Full => "Full",
        };
        let hw_str = match self.hardware_mode {
            HardwareMode::Auto => "Auto-detect",
            HardwareMode::Nvidia => "NVIDIA (forced)",
            HardwareMode::Amd => "AMD (forced)",
            HardwareMode::Cpu => "CPU (forced)",
        };
        println!("Mode: {WHITE}{BOLD}{}{RESET}  |  Hardware: {WHITE}{BOLD}{}{RESET}", mode_str, hw_str);
        println!();
    }

    /// Check all prerequisites
    fn check_prerequisites(&self) -> Result<Vec<PrerequisiteResult>> {
        let mut results = Vec::new();

        // Check Rust version
        results.push(self.check_rust_version());

        // Check Ollama
        results.push(self.check_ollama());

        // Check disk space
        results.push(self.check_disk_space());

        // Check RAM
        results.push(self.check_ram());

        // Check GPU (based on hardware mode)
        if self.hardware_mode != HardwareMode::Cpu {
            results.push(self.check_gpu());
        }

        Ok(results)
    }

    fn check_rust_version(&self) -> PrerequisiteResult {
        let output = Command::new("rustc").arg("--version").output();

        match output {
            Ok(out) if out.status.success() => {
                let version = String::from_utf8_lossy(&out.stdout);
                let version_str = version.trim();

                // Extract version number
                let parts: Vec<&str> = version_str.split_whitespace().collect();
                if parts.len() >= 2 {
                    let version_num = parts[1];
                    // Check if version is >= 1.70 (minimum for modern async features)
                    let version_parts: Vec<u32> = version_num
                        .split('.')
                        .filter_map(|s| s.parse().ok())
                        .collect();

                    if version_parts.len() >= 2 && (version_parts[0] > 1 || version_parts[1] >= 70) {
                        PrerequisiteResult {
                            name: "Rust".to_string(),
                            passed: true,
                            message: format!("v{}", version_num),
                            fix_hint: None,
                        }
                    } else {
                        PrerequisiteResult {
                            name: "Rust".to_string(),
                            passed: false,
                            message: format!("v{} (need >= 1.70)", version_num),
                            fix_hint: Some("Run: rustup update stable".to_string()),
                        }
                    }
                } else {
                    PrerequisiteResult {
                        name: "Rust".to_string(),
                        passed: true,
                        message: version_str.to_string(),
                        fix_hint: None,
                    }
                }
            }
            _ => PrerequisiteResult {
                name: "Rust".to_string(),
                passed: false,
                message: "Not installed".to_string(),
                fix_hint: Some("Install from https://rustup.rs".to_string()),
            },
        }
    }

    fn check_ollama(&self) -> PrerequisiteResult {
        // Check if Ollama is installed
        if !check_ollama_available() {
            return PrerequisiteResult {
                name: "Ollama".to_string(),
                passed: false,
                message: "Not installed".to_string(),
                fix_hint: Some("Install from https://ollama.ai/download".to_string()),
            };
        }

        // Check if Ollama is running
        let client = OllamaClient::new();
        if !client.check_ollama_running() {
            return PrerequisiteResult {
                name: "Ollama".to_string(),
                passed: false,
                message: "Installed but not running".to_string(),
                fix_hint: Some("Run: ollama serve".to_string()),
            };
        }

        // Get version
        let output = Command::new("ollama").arg("--version").output();
        let version = output
            .ok()
            .map(|o| String::from_utf8_lossy(&o.stdout).trim().to_string())
            .unwrap_or_else(|| "unknown".to_string());

        PrerequisiteResult {
            name: "Ollama".to_string(),
            passed: true,
            message: format!("{} (running)", version),
            fix_hint: None,
        }
    }

    fn check_disk_space(&self) -> PrerequisiteResult {
        // Get available disk space on the config directory
        let required_gb = match self.mode {
            SetupMode::Quick => 5,
            SetupMode::Full => 20,
        };

        #[cfg(target_os = "windows")]
        let available_gb = {
            // Use PowerShell to get disk space on Windows
            let output = Command::new("powershell")
                .args([
                    "-NoProfile",
                    "-Command",
                    "(Get-PSDrive C).Free / 1GB"
                ])
                .output();

            output
                .ok()
                .and_then(|o| {
                    String::from_utf8_lossy(&o.stdout)
                        .trim()
                        .parse::<f64>()
                        .ok()
                })
                .map(|gb| gb as u64)
                .unwrap_or(0)
        };

        #[cfg(not(target_os = "windows"))]
        let available_gb = {
            // Use df on Unix systems
            let output = Command::new("df")
                .args(["-BG", "/"])
                .output();

            output
                .ok()
                .and_then(|o| {
                    let stdout = String::from_utf8_lossy(&o.stdout);
                    stdout
                        .lines()
                        .nth(1)
                        .and_then(|line| {
                            line.split_whitespace()
                                .nth(3)
                                .and_then(|s| s.trim_end_matches('G').parse::<u64>().ok())
                        })
                })
                .unwrap_or(0)
        };

        if available_gb >= required_gb {
            PrerequisiteResult {
                name: "Disk Space".to_string(),
                passed: true,
                message: format!("{}GB available (need {}GB)", available_gb, required_gb),
                fix_hint: None,
            }
        } else {
            PrerequisiteResult {
                name: "Disk Space".to_string(),
                passed: false,
                message: format!("{}GB available (need {}GB)", available_gb, required_gb),
                fix_hint: Some("Free up disk space or use --quick mode".to_string()),
            }
        }
    }

    fn check_ram(&self) -> PrerequisiteResult {
        let required_gb: u64 = 8; // Minimum 8GB RAM

        #[cfg(target_os = "windows")]
        let available_gb = {
            let output = Command::new("powershell")
                .args([
                    "-NoProfile",
                    "-Command",
                    "(Get-CimInstance Win32_ComputerSystem).TotalPhysicalMemory / 1GB"
                ])
                .output();

            output
                .ok()
                .and_then(|o| {
                    String::from_utf8_lossy(&o.stdout)
                        .trim()
                        .parse::<f64>()
                        .ok()
                })
                .map(|gb| gb.round() as u64)
                .unwrap_or(0)
        };

        #[cfg(target_os = "macos")]
        let available_gb = {
            let output = Command::new("sysctl")
                .args(["-n", "hw.memsize"])
                .output();

            output
                .ok()
                .and_then(|o| {
                    String::from_utf8_lossy(&o.stdout)
                        .trim()
                        .parse::<u64>()
                        .ok()
                })
                .map(|bytes| bytes / 1_073_741_824)
                .unwrap_or(0)
        };

        #[cfg(target_os = "linux")]
        let available_gb = {
            let output = Command::new("free")
                .args(["-g"])
                .output();

            output
                .ok()
                .and_then(|o| {
                    let stdout = String::from_utf8_lossy(&o.stdout);
                    stdout
                        .lines()
                        .find(|line| line.starts_with("Mem:"))
                        .and_then(|line| {
                            line.split_whitespace()
                                .nth(1)
                                .and_then(|s| s.parse::<u64>().ok())
                        })
                })
                .unwrap_or(0)
        };

        #[cfg(not(any(target_os = "windows", target_os = "macos", target_os = "linux")))]
        let available_gb: u64 = 16; // Assume sufficient for unknown OS

        if available_gb >= required_gb {
            PrerequisiteResult {
                name: "RAM".to_string(),
                passed: true,
                message: format!("{}GB available", available_gb),
                fix_hint: None,
            }
        } else {
            PrerequisiteResult {
                name: "RAM".to_string(),
                passed: false,
                message: format!("{}GB available (need {}GB)", available_gb, required_gb),
                fix_hint: Some("Close other applications or use a smaller model".to_string()),
            }
        }
    }

    fn check_gpu(&self) -> PrerequisiteResult {
        match detect_gpu() {
            Ok(gpu) if gpu.gpu_type != GpuType::Cpu => {
                let vram_status = if gpu.vram_gb >= 8 {
                    format!("{}GB VRAM", gpu.vram_gb)
                } else {
                    format!("{}GB VRAM (limited)", gpu.vram_gb)
                };
                PrerequisiteResult {
                    name: "GPU".to_string(),
                    passed: true,
                    message: format!("{} ({})", gpu.name, vram_status),
                    fix_hint: None,
                }
            }
            Ok(_) => {
                // CPU-only detected
                if self.hardware_mode == HardwareMode::Auto {
                    PrerequisiteResult {
                        name: "GPU".to_string(),
                        passed: true,
                        message: "None detected (will use CPU)".to_string(),
                        fix_hint: Some("Install GPU drivers for better performance".to_string()),
                    }
                } else {
                    PrerequisiteResult {
                        name: "GPU".to_string(),
                        passed: false,
                        message: "None detected".to_string(),
                        fix_hint: Some("Check GPU drivers or use --hardware cpu".to_string()),
                    }
                }
            }
            Err(e) => PrerequisiteResult {
                name: "GPU".to_string(),
                passed: false,
                message: format!("Detection failed: {}", e),
                fix_hint: Some("Check GPU drivers or use --hardware cpu".to_string()),
            },
        }
    }

    /// Detect hardware and generate optimal configuration
    fn detect_hardware(&self) -> Result<(GpuInfo, HardwareConfig)> {
        let gpu_info = match self.hardware_mode {
            HardwareMode::Auto => detect_gpu().unwrap_or_default(),
            HardwareMode::Nvidia => {
                let gpu = detect_gpu().unwrap_or_default();
                if gpu.gpu_type == GpuType::Nvidia {
                    gpu
                } else {
                    return Err(anyhow::anyhow!("NVIDIA GPU not detected. Use --hardware auto or --hardware cpu"));
                }
            }
            HardwareMode::Amd => {
                let gpu = detect_gpu().unwrap_or_default();
                if gpu.gpu_type == GpuType::Amd {
                    gpu
                } else {
                    return Err(anyhow::anyhow!("AMD GPU not detected. Use --hardware auto or --hardware cpu"));
                }
            }
            HardwareMode::Cpu => GpuInfo::default(),
        };

        let mut config = HardwareConfig {
            gpu_type: format!("{:?}", gpu_info.gpu_type).to_lowercase(),
            gpu_name: gpu_info.name.clone(),
            vram_gb: gpu_info.vram_gb,
            use_vulkan: false,
            hsa_override: None,
            batch_size: 512,
            gpu_layers: None,
        };

        // AMD-specific optimizations
        if gpu_info.gpu_type == GpuType::Amd {
            let arch = detect_amd_architecture(&gpu_info.name);

            // RDNA 4 requires Vulkan backend
            if arch == AmdArchitecture::Rdna4 {
                config.use_vulkan = true;
            }

            // Set HSA override for compatibility
            config.hsa_override = crate::detect::get_hsa_override_version(&gpu_info.name);
        }

        // Set optimal batch size based on VRAM
        config.batch_size = match gpu_info.vram_gb {
            0..=3 => 256,
            4..=7 => 512,
            8..=15 => 1024,
            16..=23 => 2048,
            _ => 4096,
        };

        // Calculate GPU layers based on VRAM and model size
        // This is a rough heuristic - actual value depends on model
        if gpu_info.vram_gb > 0 {
            let model_layers = match gpu_info.vram_gb {
                0..=3 => 15,
                4..=7 => 35,
                8..=15 => 50,
                _ => 100, // Full offload
            };
            config.gpu_layers = Some(model_layers);
        }

        Ok((gpu_info, config))
    }

    fn print_hardware_info(&self, gpu: &GpuInfo, config: &HardwareConfig) {
        if gpu.gpu_type == GpuType::Cpu {
            println!("  {BLUE}[i]{RESET} GPU: {DIM}None detected (CPU mode){RESET}");
        } else {
            println!("  {GREEN}[OK]{RESET} GPU: {WHITE}{BOLD}{}{RESET}", gpu.name);
            println!("  {BLUE}[i]{RESET} VRAM: {}GB", gpu.vram_gb);

            if let Some(ref driver) = gpu.driver {
                println!("  {BLUE}[i]{RESET} Driver: {}", driver);
            }

            if config.use_vulkan {
                println!("  {BLUE}[i]{RESET} Backend: Vulkan (RDNA 4 optimized)");
            }

            if let Some(ref hsa) = config.hsa_override {
                println!("  {BLUE}[i]{RESET} HSA Override: {}", hsa);
            }

            println!("  {BLUE}[i]{RESET} Batch Size: {}", config.batch_size);

            if let Some(layers) = config.gpu_layers {
                println!("  {BLUE}[i]{RESET} GPU Layers: {}", layers);
            }
        }
    }

    /// Generate configuration based on detected hardware
    fn generate_config(&self, gpu: &GpuInfo, hw_config: &HardwareConfig) -> Result<RigrunConfig> {
        let model = recommend_model(gpu.vram_gb);

        let config = RigrunConfig {
            general: GeneralConfig {
                config_version: 1,
                created_at: chrono::Utc::now().to_rfc3339(),
                first_run_complete: true,
            },
            hardware: hw_config.clone(),
            model: ModelConfig {
                primary: model,
                embedding: "nomic-embed-text".to_string(),
                auto_download: true,
            },
            server: ServerConfig::default(),
            security: SecurityConfig::default(),
        };

        Ok(config)
    }

    /// Save configuration to TOML file
    fn save_config(&self, config: &RigrunConfig) -> Result<PathBuf> {
        // Ensure config directory exists
        fs::create_dir_all(&self.config_dir)?;

        let config_path = self.config_dir.join("config.toml");

        // Generate TOML content manually for better formatting and comments
        let toml_content = self.generate_toml_content(config);

        fs::write(&config_path, toml_content)?;

        Ok(config_path)
    }

    fn generate_toml_content(&self, config: &RigrunConfig) -> String {
        let mut content = String::new();

        content.push_str("# RigRun Configuration\n");
        content.push_str("# Generated by 'rigrun setup'\n");
        content.push_str(&format!("# {}\n\n", config.general.created_at));

        // General section
        content.push_str("[general]\n");
        content.push_str(&format!("config_version = {}\n", config.general.config_version));
        content.push_str(&format!("created_at = \"{}\"\n", config.general.created_at));
        content.push_str(&format!("first_run_complete = {}\n", config.general.first_run_complete));
        content.push_str("\n");

        // Hardware section
        content.push_str("[hardware]\n");
        content.push_str("# Detected hardware configuration\n");
        content.push_str(&format!("gpu_type = \"{}\"\n", config.hardware.gpu_type));
        content.push_str(&format!("gpu_name = \"{}\"\n", config.hardware.gpu_name));
        content.push_str(&format!("vram_gb = {}\n", config.hardware.vram_gb));
        content.push_str(&format!("use_vulkan = {}\n", config.hardware.use_vulkan));
        if let Some(ref hsa) = config.hardware.hsa_override {
            content.push_str(&format!("hsa_override = \"{}\"\n", hsa));
        }
        content.push_str(&format!("batch_size = {}\n", config.hardware.batch_size));
        if let Some(layers) = config.hardware.gpu_layers {
            content.push_str(&format!("gpu_layers = {}\n", layers));
        }
        content.push_str("\n");

        // Model section
        content.push_str("[model]\n");
        content.push_str("# Model settings optimized for your hardware\n");
        content.push_str(&format!("primary = \"{}\"\n", config.model.primary));
        content.push_str(&format!("embedding = \"{}\"\n", config.model.embedding));
        content.push_str(&format!("auto_download = {}\n", config.model.auto_download));
        content.push_str("\n");

        // Server section
        content.push_str("[server]\n");
        content.push_str("# Server settings\n");
        content.push_str(&format!("port = {}\n", config.server.port));
        content.push_str(&format!("host = \"{}\"\n", config.server.host));
        content.push_str(&format!("audit_logging = {}\n", config.server.audit_logging));
        content.push_str(&format!("paranoid_mode = {}\n", config.server.paranoid_mode));
        content.push_str("\n");

        // Security section
        content.push_str("[security]\n");
        content.push_str("# Security settings\n");
        content.push_str(&format!("api_key = \"{}\"\n", config.security.api_key));
        if let Some(ref key) = config.security.openrouter_key {
            content.push_str(&format!("openrouter_key = \"{}\"\n", key));
        } else {
            content.push_str("# openrouter_key = \"sk-or-...\"  # Uncomment to enable cloud fallback\n");
        }
        content.push_str(&format!("require_auth = {}\n", config.security.require_auth));

        content
    }

    /// Download the required model with progress display
    fn download_model(&self, model: &str) -> Result<String> {
        // Check if model already exists
        if is_model_available(model) {
            println!("  {GREEN}[OK]{RESET} Model {WHITE}{BOLD}{}{RESET} already downloaded", model);
            return Ok(model.to_string());
        }

        println!("  {CYAN}[...]{RESET} Downloading {WHITE}{BOLD}{}{RESET}...", model);

        // Get approximate size for user info
        let size_info = get_model_size_info(model);
        println!("  {DIM}Size: {} (one-time download){RESET}", size_info);

        let client = OllamaClient::new();
        let start = Instant::now();
        let mut last_print = Instant::now();

        client.pull_model_with_progress(model, |progress: PullProgress| {
            // Only print every 500ms to avoid flooding
            if last_print.elapsed() > Duration::from_millis(500) {
                if let Some(pct) = progress.percentage() {
                    print!("\r  {CYAN}[{:.0}%]{RESET} {}", pct, progress.status);
                    io::stdout().flush().ok();
                } else {
                    print!("\r  {CYAN}[...]{RESET} {}", progress.status);
                    io::stdout().flush().ok();
                }
                last_print = Instant::now();
            }
        })?;

        let elapsed = start.elapsed();
        println!("\r  {GREEN}[OK]{RESET} Model downloaded in {:.0}s                    ", elapsed.as_secs_f64());

        Ok(model.to_string())
    }

    /// Verify system health after setup
    fn verify_health(&self, config: &RigrunConfig) -> Result<Vec<String>> {
        let mut warnings = Vec::new();

        // Test Ollama connection
        let client = OllamaClient::new();
        if !client.check_ollama_running() {
            warnings.push("Ollama is not responding. Try: ollama serve".to_string());
            return Ok(warnings);
        }

        // Test model loading
        if !is_model_available(&config.model.primary) {
            warnings.push(format!("Model {} not found. Download with: ollama pull {}",
                config.model.primary, config.model.primary));
            return Ok(warnings);
        }

        // Run quick inference test
        print!("  {CYAN}[...]{RESET} Running inference test...");
        io::stdout().flush().ok();

        let start = Instant::now();
        let result = client.generate(&config.model.primary, "Hello, please respond with just 'OK'.");
        let elapsed = start.elapsed();

        match result {
            Ok(_response) => {
                println!("\r  {GREEN}[OK]{RESET} Inference test passed ({:.1}s)         ", elapsed.as_secs_f64());

                // Check if response indicates GPU usage issues
                if elapsed.as_secs() > 30 && config.hardware.vram_gb >= 8 {
                    warnings.push("Inference seems slow for your GPU. Check if Ollama is using GPU: ollama ps".to_string());
                }
            }
            Err(e) => {
                println!("\r  {RED}[X]{RESET} Inference test failed                ");
                warnings.push(format!("Inference failed: {}. Check model with: ollama run {}", e, config.model.primary));
            }
        }

        // Check environment variables for AMD
        if config.hardware.use_vulkan {
            let vulkan_env = std::env::var("OLLAMA_VULKAN").unwrap_or_default();
            if vulkan_env != "1" {
                warnings.push("RDNA 4 detected: Set OLLAMA_VULKAN=1 for best performance".to_string());
            }
        }

        Ok(warnings)
    }

    fn print_success(&self, gpu: &GpuInfo, config_path: &PathBuf, model: &str) {
        println!();
        println!("{GREEN}{BOLD}========================================{RESET}");
        println!("{GREEN}{BOLD}         Setup Complete!{RESET}");
        println!("{GREEN}{BOLD}========================================{RESET}");
        println!();

        // Summary
        let gpu_display = if gpu.gpu_type == GpuType::Cpu {
            "CPU Only".to_string()
        } else {
            format!("{} ({}GB VRAM)", gpu.name, gpu.vram_gb)
        };

        println!("{GREEN}[OK]{RESET} Prerequisites checked");
        println!("{GREEN}[OK]{RESET} Hardware detected: {WHITE}{BOLD}{}{RESET}", gpu_display);
        println!("{GREEN}[OK]{RESET} Configuration generated: {WHITE}{}{RESET}", config_path.display());
        println!("{GREEN}[OK]{RESET} Model downloaded: {WHITE}{BOLD}{}{RESET}", model);
        println!("{GREEN}[OK]{RESET} Health check passed");
        println!();

        // Environment variables to set (if needed)
        if gpu.gpu_type == GpuType::Amd {
            let arch = detect_amd_architecture(&gpu.name);
            if arch == AmdArchitecture::Rdna4 {
                println!("{YELLOW}[!]{RESET} For best performance, set this environment variable:");
                println!("    {CYAN}OLLAMA_VULKAN=1{RESET}");
                println!();
            }
        }

        // Next steps
        println!("{BRIGHT_CYAN}{BOLD}Next Steps:{RESET}");
        println!();
        println!("  1. Start the server:");
        println!("     {CYAN}rigrun serve{RESET}");
        println!();
        println!("  2. Or try a quick question:");
        println!("     {CYAN}rigrun ask \"Explain recursion\"{RESET}");
        println!();
        println!("  3. Or start interactive chat:");
        println!("     {CYAN}rigrun chat{RESET}");
        println!();

        // Config location
        println!("{DIM}Configuration: {}{RESET}", config_path.display());
        println!("{DIM}Logs: ~/.rigrun/audit.log{RESET}");
        println!();
    }
}

/// Get config directory path
fn get_config_dir() -> Result<PathBuf> {
    let home = dirs::home_dir().context("Could not find home directory")?;
    Ok(home.join(".rigrun"))
}

/// Get approximate model size for display
fn get_model_size_info(model: &str) -> &'static str {
    let model_lower = model.to_lowercase();

    if model_lower.contains("1.5b") {
        "~1 GB"
    } else if model_lower.contains("3b") {
        "~2 GB"
    } else if model_lower.contains("7b") {
        "~4 GB"
    } else if model_lower.contains("8b") {
        "~5 GB"
    } else if model_lower.contains("13b") || model_lower.contains("14b") {
        "~8 GB"
    } else if model_lower.contains("16b") {
        "~10 GB"
    } else if model_lower.contains("22b") {
        "~13 GB"
    } else if model_lower.contains("30b") || model_lower.contains("32b") {
        "~18 GB"
    } else if model_lower.contains("70b") || model_lower.contains("72b") {
        "~40 GB"
    } else {
        "Unknown size"
    }
}

/// Public function to run setup from CLI
pub fn run_setup(quick: bool, full: bool, hardware: Option<String>) -> Result<SetupResult> {
    let mode = if full {
        SetupMode::Full
    } else {
        SetupMode::Quick
    };

    let hardware_mode = match hardware {
        Some(hw) => hw.parse().map_err(|e: String| anyhow::anyhow!(e))?,
        None => HardwareMode::Auto,
    };

    let wizard = SetupWizard::new(mode, hardware_mode)?;
    wizard.run()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_hardware_mode_parsing() {
        assert_eq!("auto".parse::<HardwareMode>().unwrap(), HardwareMode::Auto);
        assert_eq!("nvidia".parse::<HardwareMode>().unwrap(), HardwareMode::Nvidia);
        assert_eq!("amd".parse::<HardwareMode>().unwrap(), HardwareMode::Amd);
        assert_eq!("cpu".parse::<HardwareMode>().unwrap(), HardwareMode::Cpu);
        assert_eq!("AUTO".parse::<HardwareMode>().unwrap(), HardwareMode::Auto);
        assert!("invalid".parse::<HardwareMode>().is_err());
    }

    #[test]
    fn test_secure_key_generation() {
        let key1 = generate_secure_key();
        let key2 = generate_secure_key();

        assert!(key1.starts_with("rr-"));
        assert!(key2.starts_with("rr-"));
        assert_ne!(key1, key2);
        assert_eq!(key1.len(), 35); // "rr-" + 32 chars
    }

    #[test]
    fn test_model_size_info() {
        assert_eq!(get_model_size_info("qwen2.5-coder:7b"), "~4 GB");
        assert_eq!(get_model_size_info("qwen2.5-coder:14b"), "~8 GB");
        assert_eq!(get_model_size_info("qwen2.5-coder:32b"), "~18 GB");
    }

    #[test]
    fn test_default_config() {
        let config = RigrunConfig::default();
        assert_eq!(config.general.config_version, 1);
        assert_eq!(config.server.port, 8787);
        assert!(!config.security.require_auth);
    }
}
